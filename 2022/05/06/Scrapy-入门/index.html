<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>Scrapy-入门 | zhaoyupeng_blog</title><meta name="author" content="zhaoyupeng"><meta name="copyright" content="zhaoyupeng"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="入门教程学习目标完成下列任务:  创建一个Scrapy项目  定义提取的结构化数据(Item)  编写爬取网站的 spider 并提取出结构化数据(Item)  编写 Item Pipeline 来存储提取到的Item(即结构化数据)    创建项目在开始爬取之前，您必须创建一个新的Scrapy项目。 进入您打算存储代码的目录中，运行下列命令:  复制代码  scrapy startproject">
<meta property="og:type" content="article">
<meta property="og:title" content="Scrapy-入门">
<meta property="og:url" content="http://example.com/2022/05/06/Scrapy-%E5%85%A5%E9%97%A8/index.html">
<meta property="og:site_name" content="zhaoyupeng_blog">
<meta property="og:description" content="入门教程学习目标完成下列任务:  创建一个Scrapy项目  定义提取的结构化数据(Item)  编写爬取网站的 spider 并提取出结构化数据(Item)  编写 Item Pipeline 来存储提取到的Item(即结构化数据)    创建项目在开始爬取之前，您必须创建一个新的Scrapy项目。 进入您打算存储代码的目录中，运行下列命令:  复制代码  scrapy startproject">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2022-05-06T13:40:09.000Z">
<meta property="article:modified_time" content="2022-05-06T13:40:14.011Z">
<meta property="article:author" content="zhaoyupeng">
<meta name="twitter:card" content="summary"><link rel="shortcut icon" href="/img/klee-2.jpg"><link rel="canonical" href="http://example.com/2022/05/06/Scrapy-%E5%85%A5%E9%97%A8/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Scrapy-入门',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-05-06 21:40:14'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="zhaoyupeng_blog" type="application/atom+xml">
</head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/klee-1.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">8</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">0</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">0</div></a></div><hr/></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">zhaoyupeng_blog</a></span><div id="menus"><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Scrapy-入门</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-05-06T13:40:09.000Z" title="发表于 2022-05-06 21:40:09">2022-05-06</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-05-06T13:40:14.011Z" title="更新于 2022-05-06 21:40:14">2022-05-06</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="Scrapy-入门"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="入门教程"><a href="#入门教程" class="headerlink" title="入门教程"></a>入门教程</h1><h4 id="学习目标"><a href="#学习目标" class="headerlink" title="学习目标"></a>学习目标</h4><p>完成下列任务:</p>
<ul>
<li><p>创建一个Scrapy项目</p>
</li>
<li><p>定义提取的结构化数据(Item)</p>
</li>
<li><p>编写爬取网站的 spider 并提取出结构化数据(Item)</p>
</li>
<li><p>编写 Item Pipeline 来存储提取到的Item(即结构化数据)</p>
</li>
<li></li>
</ul>
<h3 id="创建项目"><a href="#创建项目" class="headerlink" title="创建项目"></a>创建项目</h3><p>在开始爬取之前，您必须创建一个新的<code>Scrapy</code>项目。 进入您打算存储代码的目录中，运行下列命令:</p>
<p> 复制代码</p>
<ol>
<li><code>scrapy startproject tutorial</code></li>
</ol>
<p>运行过程：</p>
<p><img src="https://static.sitestack.cn/projects/piaosanlang-spiders/b0939eadc6fdbb910806f8ccb68db4ad.gif" alt="入门教程 - 图1"></p>
<p>该命令将会创建包含下列内容的 tutorial 目录:</p>
<p>这些文件分别是:</p>
<p> 复制代码</p>
<ol>
<li><code>scrapy.cfg: 项目的配置文件；（用于发布到服务器）</code></li>
<li><code>tutorial/: 该项目文件夹。之后将在此编写Python代码。</code></li>
<li><code>tutorial/items.py: 项目中的item文件;（定义结构化数据字段field）.</code></li>
<li><code>tutorial/pipelines.py: 项目中的pipelines文件;（用于存放执行后期数据处理的功能，定义如何存储结构化数据)</code></li>
<li><code>tutorial/settings.py: 项目的设置文件；(如何修改User-Agent，设置爬取时间间隔，设置代理，配置中间件等等)</code></li>
<li><code>tutorial/spiders/: 放置spider代码的目录;（编写爬取网站规则）</code></li>
</ol>
<h3 id="定义Item"><a href="#定义Item" class="headerlink" title="定义Item"></a>定义Item</h3><p>Item 定义结构化数据字段，用来保存爬取到的数据；其使用方法和python字典类似</p>
<p>可以通过创建一个 <code>scrapy.Item</code> 类， 并且定义类型为 <code>scrapy.Field</code>的类属性来定义一个Item。</p>
<p>首先根据需要从<a target="_blank" rel="noopener" href="http://hr.tencent.com/position.php?&start=0#a">腾讯招聘</a>获取到的数据对item进行建模。 我们需要从<code>腾讯招聘</code>中获取 职位名称、<code>职位详情页url</code>、职位类别、人数、工作地点以及发布时间。 对此，在item中定义相应的字段。编辑 <code>tutorial</code> 目录中的 <code>items.py</code> 文件:</p>
<p> 复制代码</p>
<ol>
<li><p><code>import scrapy</code></p>
</li>
<li><p><code>class RecruitItem(scrapy.Item):</code></p>
</li>
<li><p><code>name = scrapy.Field()</code></p>
</li>
<li><p><code>detailLink = scrapy.Field()</code></p>
</li>
<li><p><code>catalog = scrapy.Field()</code></p>
</li>
<li><p><code>recruitNumber = scrapy.Field()</code></p>
</li>
<li><p><code>workLocation = scrapy.Field()</code></p>
</li>
<li><p><code>publishTime = scrapy.Field()</code></p>
</li>
</ol>
<h3 id="编写第一个爬虫-Spider"><a href="#编写第一个爬虫-Spider" class="headerlink" title="编写第一个爬虫(Spider)"></a>编写第一个爬虫(Spider)</h3><p>Spider是开发者编写用于从单个网站(或者一些网站)爬取数据的类。</p>
<p>创建一个Spider，必须继承 ‘scrapy.Spider’ 类， 需要定义以下三个属性:</p>
<ul>
<li><p>name:</p>
<p>  spider名字；必须是唯一的</p>
</li>
<li><p>start_urls:</p>
<p>  初始的URL列表</p>
</li>
<li><p>parse(self, response)：</p>
<p>  每个初始URL完成下载后被调用</p>
<p>  这个函数要完成的功能：</p>
</li>
</ul>
<p> 复制代码</p>
<ol>
<li><code>1.负责解析返回的网页数据(response.body)，提取结构化数据(生成item)</code></li>
<li><code>2.生成需要下一页的请求URL。</code></li>
</ol>
<p>以下为我们的第一个Spider代码，保存在 tutorial&#x2F;spiders 目录下的 tencent_spider.py 文件中:</p>
<p> 复制代码</p>
<ol>
<li><p><code>import scrapy</code></p>
</li>
<li><p><code>class RecruitSpider(scrapy.spiders.Spider):</code></p>
</li>
<li><p><code>name = &quot;tencent&quot;</code></p>
</li>
<li><p><code>allowed_domains = [&quot;hr.tencent.com&quot;]</code></p>
</li>
<li><p><code>start_urls = [</code></p>
</li>
<li><p><code>&quot;http://hr.tencent.com/position.php?&amp;start=0#a&quot;</code></p>
</li>
<li><p><code>]</code></p>
</li>
<li><p><code>def parse(self, response):</code></p>
</li>
<li><p><code>f = open(&#39;tengxun.txt&#39;, &#39;wb&#39;)</code></p>
</li>
<li><p><code>f.write(response.body)</code></p>
</li>
<li><p><code>f.close()</code></p>
</li>
</ol>
<h3 id="爬取"><a href="#爬取" class="headerlink" title="爬取"></a>爬取</h3><p>进入项目的根目录，执行下列命令启动spider:</p>
<p> 复制代码</p>
<ol>
<li><code>scrapy crawl tencent</code></li>
</ol>
<p>crawl tencent 启动用于爬取 tencent 的spider，您将得到类似的输出:</p>
<p><img src="https://static.sitestack.cn/projects/piaosanlang-spiders/919526005b0a52806c14376101fa97cd.gif" alt="入门教程 - 图2"></p>
<p>现在，查看当前目录，会注意到有文件被创建了: tengxun.txt,正如我们的 parse 方法里做的一样。</p>
<p><strong>注意，在刚启动的时候会有一段error信息，不用理会</strong></p>
<p>在第六天作业里面有说明原因</p>
<p> 复制代码</p>
<ol>
<li><code>2016-08-11 13:07:35 [boto] ERROR: Caught exception reading instance data</code></li>
<li><code>Traceback (most recent call last):</code></li>
<li><code>File &quot;/usr/lib/python2.7/dist-packages/boto/utils.py&quot;, line 210, in retry_url</code></li>
<li><code>r = opener.open(req, timeout=timeout)</code></li>
<li><code>File &quot;/usr/lib/python2.7/urllib2.py&quot;, line 429, in open</code></li>
<li><code>response = self._open(req, data)</code></li>
<li><code>File &quot;/usr/lib/python2.7/urllib2.py&quot;, line 447, in _open</code></li>
<li><code>&#39;_open&#39;, req)</code></li>
<li><code>File &quot;/usr/lib/python2.7/urllib2.py&quot;, line 407, in _call_chain</code></li>
<li><code>result = func(*args)</code></li>
<li><code>File &quot;/usr/lib/python2.7/urllib2.py&quot;, line 1228, in http_open</code></li>
<li><code>return self.do_open(httplib.HTTPConnection, req)</code></li>
<li><code>File &quot;/usr/lib/python2.7/urllib2.py&quot;, line 1198, in do_open</code></li>
<li><code>raise URLError(err)</code></li>
<li><code>URLError: &lt;urlopen error timed out&gt;</code></li>
</ol>
<h3 id="刚才发生了什么？"><a href="#刚才发生了什么？" class="headerlink" title="刚才发生了什么？"></a>刚才发生了什么？</h3><p>Scrapy为Spider的 start_urls 属性中的每个URL创建了 <code>scrapy.Request</code> 对象，并将 parse 方法作为回调函数(callback)赋值给了Request。</p>
<p>Request对象经过调度，执行生成 <code>scrapy.http.Response</code> 对象并送回给<code>parse()</code> 方法。</p>
<h3 id="提取Item"><a href="#提取Item" class="headerlink" title="提取Item"></a>提取Item</h3><h4 id="Selectors选择器简介"><a href="#Selectors选择器简介" class="headerlink" title="Selectors选择器简介"></a>Selectors选择器简介</h4><p><code>Scrapy Selectors</code> 内置<code>XPath</code> 和 <code>CSS Selector</code> 表达式机制</p>
<p>XPath表达式的例子及对应的含义:</p>
<p> 复制代码</p>
<ol>
<li><code>/html/head/title: 选择&lt;HTML&gt;文档中 &lt;head&gt; 标签内的 &lt;title&gt; 元素</code></li>
<li><code>/html/head/title/text(): 选择上面提到的 &lt;title&gt; 元素的文字</code></li>
<li><code>//td: 选择所有的 &lt;td&gt; 元素</code></li>
<li><code>//div[@class=&quot;mine&quot;]: 选择所有具有 class=&quot;mine&quot; 属性的 div 元素</code></li>
</ol>
<p>Selector有四个基本的方法:</p>
<p> 复制代码</p>
<ol>
<li><code>xpath(): 传入xpath表达式，返回该表达式所对应的所有节点的selector list列表 。</code></li>
<li><code>css(): 传入CSS表达式，返回该表达式所对应的所有节点的selector list列表.</code></li>
<li><code>extract(): 序列化该节点为unicode字符串并返回list。</code></li>
<li><code>re(): 根据传入的正则表达式对数据进行提取，返回unicode字符串list列表。</code></li>
</ol>
<h3 id="尝试Selector选择器"><a href="#尝试Selector选择器" class="headerlink" title="尝试Selector选择器"></a>尝试Selector选择器</h3><p>为了介绍Selector的使用方法，接下来我们将要使用内置的 scrapy shell 。Scrapy Shell需要您预装好IPython(一个扩展的Python终端)。</p>
<p>您需要进入项目的根目录，执行下列命令来启动shell:</p>
<p> 复制代码</p>
<ol>
<li><code>scrapy shell &quot;http://hr.tencent.com/position.php?&amp;start=0#a&quot;</code></li>
</ol>
<p>注解:当您在终端运行Scrapy时，请一定记得给url地址加上引号，否则包含参数的url(例如 &amp; 字符)会导致Scrapy运行失败。</p>
<p>shell的输出类似:</p>
<p><img src="https://static.sitestack.cn/projects/piaosanlang-spiders/2a926bfd0a51273e640617660ec14b76.gif" alt="入门教程 - 图3"></p>
<p>当shell载入后，将得到一个包含response数据的本地 <code>response</code> 变量。输入 <code>response.body</code>将输出response的包体， 输出 <code>response.headers</code> 可以看到response的包头。</p>
<ul>
<li>当输入 <code>response.selector</code> 时， 将获取到一个response 初始化的类 <code>Selector</code> 的对象</li>
<li>此时，可以通过使用 response.selector.xpath() 或 response.selector.css() 来对 response 进行查询。</li>
<li>或者，scrapy也对 response.selector.xpath() 及 response.selector.css() 提供了一些快捷方式, 例如 response.xpath() 或 response.css()</li>
</ul>
<p>让我们来试试:</p>
<p> 复制代码</p>
<ol>
<li><p><code>response.xpath(&#39;//title&#39;)</code></p>
</li>
<li><p><code>[&lt;Selector xpath=&#39;//title&#39; data=u&#39;&lt;title&gt;\u804c\u4f4d\u641c\u7d22 | \u793e\u4f1a\u62db\u8058 | Tencent \u817e\u8baf\u62db\u8058&lt;/title&#39;&gt;]</code></p>
</li>
<li><p><code>response.xpath(&#39;//title&#39;).extract()</code></p>
</li>
<li><p><code>[u&#39;&lt;title&gt;\u804c\u4f4d\u641c\u7d22 | \u793e\u4f1a\u62db\u8058 | Tencent \u817e\u8baf\u62db\u8058&lt;/title&gt;&#39;]</code></p>
</li>
<li><p><code>print response.xpath(&#39;//title&#39;).extract()[0]</code></p>
</li>
<li><p><code>&lt;title&gt;职位搜索 | 社会招聘 | Tencent 腾讯招聘&lt;/title&gt;</code></p>
</li>
<li><p><code>response.xpath(&#39;//title/text()&#39;)</code></p>
</li>
<li><p><code>&lt;Selector xpath=&#39;//title/text()&#39; data=u&#39;\u804c\u4f4d\u641c\u7d22 | \u793e\u4f1a\u62db\u8058 | Tencent \u817e\u8baf\u62db\u8058&#39;&gt;</code></p>
</li>
<li><p><code>response.xpath(&#39;//title/text()&#39;)[0].extract()</code></p>
</li>
<li><p><code>u&#39;\u804c\u4f4d\u641c\u7d22 | \u793e\u4f1a\u62db\u8058 | Tencent \u817e\u8baf\u62db\u8058&#39;</code></p>
</li>
<li><p><code>print response.xpath(&#39;//title/text()&#39;)[0].extract()</code></p>
</li>
<li><p><code>职位搜索 | 社会招聘 | Tencent 腾讯招聘</code></p>
</li>
<li><p><code>response.xpath(&#39;//title/text()&#39;).re(&#39;(\w+):&#39;)</code></p>
</li>
<li><p><code>[u&#39;\u804c\u4f4d\u641c\u7d22&#39;,</code></p>
</li>
<li><p><code>u&#39;\u793e\u4f1a\u62db\u8058&#39;,</code></p>
</li>
<li><p><code>u&#39;Tencent&#39;,</code></p>
</li>
<li><p><code>u&#39;\u817e\u8baf\u62db\u8058&#39;]</code></p>
</li>
</ol>
<h3 id="提取数据"><a href="#提取数据" class="headerlink" title="提取数据"></a>提取数据</h3><p>现在，我们来尝试从这些页面中提取些有用的数据。</p>
<p>我们可以通过XPath选择该页面中网站列表里所有 <code>lass=even</code> 元素:</p>
<p> 复制代码</p>
<ol>
<li><code>site = response.xpath(&#39;//*[@class=&quot;even&quot;]&#39;)</code></li>
</ol>
<p>职位名称:</p>
<p> 复制代码</p>
<ol>
<li><code>print site[0].xpath(&#39;./td[1]/a/text()&#39;).extract()[0]</code></li>
<li><code>TEG15-运营开发工程师（深圳）</code></li>
</ol>
<p>职位名称详情页:</p>
<p> 复制代码</p>
<ol>
<li><code>print site[0].xpath(&#39;./td[1]/a/@href&#39;).extract()[0]</code></li>
<li><code>position_detail.php?id=20744&amp;keywords=&amp;tid=0&amp;lid=0</code></li>
</ol>
<p>职位类别:</p>
<p> 复制代码</p>
<ol>
<li><code>print site[0].xpath(&#39;./td[2]/text()&#39;).extract()[0]</code></li>
<li><code>技术类</code></li>
</ol>
<p>对于 <code>.xpath()</code> 调用返回<code>selector</code>组成的<code>list</code>，因此可以拼接更多的 .xpath() 来进一步获取某个节点。</p>
<p> 复制代码</p>
<ol>
<li><code>for sel in response.xpath(&#39;//*[@class=&quot;even&quot;]&#39;):</code></li>
<li><code>name = sel.xpath(&#39;./td[1]/a/text()&#39;).extract()[0]</code></li>
<li><code>detailLink = sel.xpath(&#39;./td[1]/a/@href&#39;).extract()[0]</code></li>
<li><code>catalog = sel.xpath(&#39;./td[2]/text()&#39;).extract()[0]</code></li>
<li><code>recruitNumber = sel.xpath(&#39;./td[3]/text()&#39;).extract()[0]</code></li>
<li><code>workLocation = sel.xpath(&#39;./td[4]/text()&#39;).extract()[0]</code></li>
<li><code>publishTime = sel.xpath(&#39;./td[5]/text()&#39;).extract()[0]</code></li>
<li><code>print name, detailLink, catalog,recruitNumber,workLocation,publishTime</code></li>
</ol>
<p>在我们的<code>tencent_spider.py</code>文件修改成如下代码:</p>
<p> 复制代码</p>
<ol>
<li><p><code>import scrapy</code></p>
</li>
<li><p><code>class RecruitSpider(scrapy.spiders.Spider):</code></p>
</li>
<li><p><code>name = &quot;tencent&quot;</code></p>
</li>
<li><p><code>allowed_domains = [&quot;hr.tencent.com&quot;]</code></p>
</li>
<li><p><code>start_urls = [</code></p>
</li>
<li><p><code>&quot;http://hr.tencent.com/position.php?&amp;start=0#a&quot;</code></p>
</li>
<li><p><code>]</code></p>
</li>
<li><p><code>def parse(self, response):</code></p>
</li>
<li><p><code>for sel in response.xpath(&#39;//*[@class=&quot;even&quot;]&#39;):</code></p>
</li>
<li><p><code>name = sel.xpath(&#39;./td[1]/a/text()&#39;).extract()[0]</code></p>
</li>
<li><p><code>detailLink = sel.xpath(&#39;./td[1]/a/@href&#39;).extract()[0]</code></p>
</li>
<li><p><code>catalog = sel.xpath(&#39;./td[2]/text()&#39;).extract()[0]</code></p>
</li>
<li><p><code>recruitNumber = sel.xpath(&#39;./td[3]/text()&#39;).extract()[0]</code></p>
</li>
<li><p><code>workLocation = sel.xpath(&#39;./td[4]/text()&#39;).extract()[0]</code></p>
</li>
<li><p><code>publishTime = sel.xpath(&#39;./td[5]/text()&#39;).extract()[0]</code></p>
</li>
<li><p><code>print name, detailLink, catalog,recruitNumber,workLocation,publishTime</code></p>
</li>
</ol>
<p>如图所示：</p>
<p><img src="https://static.sitestack.cn/projects/piaosanlang-spiders/10efeb366ce0b9a924778f8269880ba5.png" alt="入门教程 - 图4"></p>
<p>现在尝试再次爬取<code>hr.tencent.com</code>，您将看到爬取到的网站信息被成功输出:</p>
<p> 复制代码</p>
<ol>
<li><code>scrapy crawl tencent</code></li>
</ol>
<p>运行过程：</p>
<p><img src="https://static.sitestack.cn/projects/piaosanlang-spiders/f8605ad6da5b180c4ba5bd0f82c0e16d.gif" alt="入门教程 - 图5"></p>
<h3 id="使用item"><a href="#使用item" class="headerlink" title="使用item"></a>使用item</h3><p>Item 对象是自定义的python字典。可以使用标准的字典语法来获取到其每个字段的值。</p>
<p>输入 `scrapy shell’</p>
<p> 复制代码</p>
<ol>
<li><p><code>import scrapy</code></p>
</li>
<li><p><code>class RecruitItem(scrapy.Item):</code></p>
</li>
<li><p><code>name = scrapy.Field()</code></p>
</li>
<li><p><code>detailLink = scrapy.Field()</code></p>
</li>
<li><p><code>catalog = scrapy.Field()</code></p>
</li>
<li><p><code>recruitNumber = scrapy.Field()</code></p>
</li>
<li><p><code>workLocation = scrapy.Field()</code></p>
</li>
<li><p><code>publishTime = scrapy.Field()</code></p>
</li>
<li><p><code>item = RecruitItem()</code></p>
</li>
<li><p><code>item[&#39;name&#39;] = &#39;sanlang&#39;</code></p>
</li>
<li><p><code>item[&#39;name&#39;]</code></p>
</li>
<li><p><code>&#39;sanlang&#39;</code></p>
</li>
</ol>
<p>一般来说，Spider将会将爬取到的数据以Item对象返回。所以为了将爬取的数据返回，最终<code>tencent_spider.py</code>代码将是:</p>
<p> 复制代码</p>
<ol>
<li><p><code>import scrapy</code></p>
</li>
<li><p><code>from tutorial.items import RecruitItem</code></p>
</li>
<li><p><code>class RecruitSpider(scrapy.spiders.Spider):</code></p>
</li>
<li><p><code>name = &quot;tencent&quot;</code></p>
</li>
<li><p><code>allowed_domains = [&quot;hr.tencent.com&quot;]</code></p>
</li>
<li><p><code>start_urls = [</code></p>
</li>
<li><p><code>&quot;http://hr.tencent.com/position.php?&amp;start=0#a&quot;</code></p>
</li>
<li><p><code>]</code></p>
</li>
<li><p><code>def parse(self, response):</code></p>
</li>
<li><p><code>for sel in response.xpath(&#39;//*[@class=&quot;even&quot;]&#39;):</code></p>
</li>
<li><p><code>name = sel.xpath(&#39;./td[1]/a/text()&#39;).extract()[0]</code></p>
</li>
<li><p><code>detailLink = sel.xpath(&#39;./td[1]/a/@href&#39;).extract()[0]</code></p>
</li>
<li><p><code>catalog = sel.xpath(&#39;./td[2]/text()&#39;).extract()[0]</code></p>
</li>
<li><p><code>recruitNumber = sel.xpath(&#39;./td[3]/text()&#39;).extract()[0]</code></p>
</li>
<li><p><code>workLocation = sel.xpath(&#39;./td[4]/text()&#39;).extract()[0]</code></p>
</li>
<li><p><code>publishTime = sel.xpath(&#39;./td[5]/text()&#39;).extract()[0]</code></p>
</li>
<li><p><code>print name, detailLink, catalog,recruitNumber,workLocation,publishTime</code></p>
</li>
<li><p><code>item = RecruitItem()</code></p>
</li>
<li><p><code>item[&#39;name&#39;]=name.encode(&#39;utf-8&#39;)</code></p>
</li>
<li><p><code>item[&#39;detailLink&#39;]=detailLink.encode(&#39;utf-8&#39;)</code></p>
</li>
<li><p><code>item[&#39;catalog&#39;]=catalog.encode(&#39;utf-8&#39;)</code></p>
</li>
<li><p><code>item[&#39;recruitNumber&#39;]=recruitNumber.encode(&#39;utf-8&#39;)</code></p>
</li>
<li><p><code>item[&#39;workLocation&#39;]=workLocation.encode(&#39;utf-8&#39;)</code></p>
</li>
<li><p><code>item[&#39;publishTime&#39;]=publishTime.encode(&#39;utf-8&#39;)</code></p>
</li>
<li><p><code>yield item</code></p>
</li>
</ol>
<p>现在对<code>hr.tencent.com</code>进行爬取将会产生 RecruitItem 对象:</p>
<p>运行过程：</p>
<p><img src="https://static.sitestack.cn/projects/piaosanlang-spiders/0dc4e83404d6b04c66252fcff2123a97.gif" alt="入门教程 - 图6"></p>
<h3 id="保存爬取到的数据"><a href="#保存爬取到的数据" class="headerlink" title="保存爬取到的数据"></a>保存爬取到的数据</h3><p>最简单存储爬取的数据的方式是使用 <code>Feed exports</code>:</p>
<p> 复制代码</p>
<ol>
<li><code>scrapy crawl tencent -o items.json</code></li>
</ol>
<p>该命令将采用 JSON 格式对爬取的数据进行序列化，生成 items.json 文件。</p>
<p>如果需要对爬取到的item做更多更为复杂的操作，您可以编写 Item Pipeline 。 类似于我们在创建项目时对Item做的，用于您编写自己的 tutorial&#x2F;pipelines.py 也被创建。 不过如果您仅仅想要保存item，您不需要实现任何的pipeline。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="http://example.com">zhaoyupeng</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://example.com/2022/05/06/Scrapy-%E5%85%A5%E9%97%A8/">http://example.com/2022/05/06/Scrapy-%E5%85%A5%E9%97%A8/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://example.com" target="_blank">zhaoyupeng_blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/gh/overtrue/share.js@master/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2022/05/11/AOE%E7%BD%91%E7%BB%9C%E5%9B%BE/"><img class="prev-cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">AOE网络图</div></div></a></div><div class="next-post pull-right"><a href="/2022/05/06/Regular-Expression/"><img class="next-cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Regular Expression</div></div></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/klee-1.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">zhaoyupeng</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">8</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">0</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">0</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/ZhaoYuPengGit"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B"><span class="toc-number">1.</span> <span class="toc-text">入门教程</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AD%A6%E4%B9%A0%E7%9B%AE%E6%A0%87"><span class="toc-number">1.0.0.1.</span> <span class="toc-text">学习目标</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%9B%E5%BB%BA%E9%A1%B9%E7%9B%AE"><span class="toc-number">1.0.1.</span> <span class="toc-text">创建项目</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9A%E4%B9%89Item"><span class="toc-number">1.0.2.</span> <span class="toc-text">定义Item</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BC%96%E5%86%99%E7%AC%AC%E4%B8%80%E4%B8%AA%E7%88%AC%E8%99%AB-Spider"><span class="toc-number">1.0.3.</span> <span class="toc-text">编写第一个爬虫(Spider)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%88%AC%E5%8F%96"><span class="toc-number">1.0.4.</span> <span class="toc-text">爬取</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%9A%E6%89%8D%E5%8F%91%E7%94%9F%E4%BA%86%E4%BB%80%E4%B9%88%EF%BC%9F"><span class="toc-number">1.0.5.</span> <span class="toc-text">刚才发生了什么？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8F%90%E5%8F%96Item"><span class="toc-number">1.0.6.</span> <span class="toc-text">提取Item</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Selectors%E9%80%89%E6%8B%A9%E5%99%A8%E7%AE%80%E4%BB%8B"><span class="toc-number">1.0.6.1.</span> <span class="toc-text">Selectors选择器简介</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B0%9D%E8%AF%95Selector%E9%80%89%E6%8B%A9%E5%99%A8"><span class="toc-number">1.0.7.</span> <span class="toc-text">尝试Selector选择器</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8F%90%E5%8F%96%E6%95%B0%E6%8D%AE"><span class="toc-number">1.0.8.</span> <span class="toc-text">提取数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8item"><span class="toc-number">1.0.9.</span> <span class="toc-text">使用item</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BF%9D%E5%AD%98%E7%88%AC%E5%8F%96%E5%88%B0%E7%9A%84%E6%95%B0%E6%8D%AE"><span class="toc-number">1.0.10.</span> <span class="toc-text">保存爬取到的数据</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2023/03/04/chatgpt-zh-extension/" title="chatgpt-zh-extension"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="chatgpt-zh-extension"/></a><div class="content"><a class="title" href="/2023/03/04/chatgpt-zh-extension/" title="chatgpt-zh-extension">chatgpt-zh-extension</a><time datetime="2023-03-04T09:59:25.000Z" title="发表于 2023-03-04 17:59:25">2023-03-04</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/05/25/vcpkg/" title="vcpkg"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="vcpkg"/></a><div class="content"><a class="title" href="/2022/05/25/vcpkg/" title="vcpkg">vcpkg</a><time datetime="2022-05-25T15:35:56.000Z" title="发表于 2022-05-25 23:35:56">2022-05-25</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/05/23/CGI/" title="CGI"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="CGI"/></a><div class="content"><a class="title" href="/2022/05/23/CGI/" title="CGI">CGI</a><time datetime="2022-05-23T15:35:49.000Z" title="发表于 2022-05-23 23:35:49">2022-05-23</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/05/23/%E6%8A%98%E5%8D%8A%E6%9F%A5%E6%89%BE/" title="折半查找"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="折半查找"/></a><div class="content"><a class="title" href="/2022/05/23/%E6%8A%98%E5%8D%8A%E6%9F%A5%E6%89%BE/" title="折半查找">折半查找</a><time datetime="2022-05-22T16:42:32.000Z" title="发表于 2022-05-23 00:42:32">2022-05-23</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/05/11/AOE%E7%BD%91%E7%BB%9C%E5%9B%BE/" title="AOE网络图"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="AOE网络图"/></a><div class="content"><a class="title" href="/2022/05/11/AOE%E7%BD%91%E7%BB%9C%E5%9B%BE/" title="AOE网络图">AOE网络图</a><time datetime="2022-05-11T09:59:25.000Z" title="发表于 2022-05-11 17:59:25">2022-05-11</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2023 By zhaoyupeng</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.js"></script><script>var preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',preloader.endLoading())</script><div class="js-pjax"></div><script id="canvas_nest" defer="defer" color="124,221,255" opacity="0.7" zIndex="-1" count="70" mobile="true" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-nest.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>